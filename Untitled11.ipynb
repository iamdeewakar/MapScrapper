{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install selenium\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c8BiKXwGa4o",
        "outputId": "e67517de-f2db-4606-bc07-f46673fdd585"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.21.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.25.1)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.11.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP8IBF9LFtk9",
        "outputId": "acf0f380-320c-45a6-b58c-8fa9c198fc58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve https://www.adecco.ca/en-ca/locations/quebec-quebec-staffing-agencies/adca_026626/?utm_source=gmb&utm_medium=yext with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve https://www.roberthalf.com/ca/fr/nos-bureaux/qc-ville-de-quebec?utm_source=gmb_listing&utm_medium=organic&utm_campaign=local_listing with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve https://www.randstad.ca/fr/jobs/quebec/quebec/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=quebec with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve https://lavora.ca/ with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve https://ca.drakeintl.com/: HTTPSConnectionPool(host='ca.drakeintl.com', port=443): Read timed out. (read timeout=10)\n",
            "Failed to retrieve https://ca.drakeintl.com/ with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve http://www.extraressources.ca/?utm_source=google&utm_medium=organic&utm_campaign=myBusiness&utm_term=bureau-ste-foy&utm_content=bureau-ste-foy with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve https://www.manpower.ca/en/about-us/locations/quebec,-qc?utm_source=G&utm_medium=lpm&utm_campaign=manpowerlpm with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve https://www.randstad.ca/fr/jobs/quebec/levis/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=levis with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve https://www.kellyservices.ca/?utm_source=gmb-listing&utm_medium=organic&utm_campaign=all_both_local-listings&utm_content=quebeccity-qc-can with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve https://www.talentworld.com/ with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve https://ctmservices.ca/ with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve https://grouperp.ca/ with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve https://www.vaco.com/locations/quebec-city-quebec/? with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve http://groupe-erci.ca/ with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve http://www.alliancerecrutement.ca/ with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve https://www.ancia.ca/ with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve http://www.ids-recrutement.com/ with Selenium: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "QuebecCity.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "# Your API key (replace with your actual API key)\n",
        "API_KEY = 'AIzaSyD3GG7Qq1XgRMAcjPejT9spgnR4RZ9xzbU'\n",
        "\n",
        "# Define the search query and location\n",
        "query = 'Recruitment Companies in Quebec City'\n",
        "location = '46.829853','-71.254028'  # Latitude and Longitude for Toronto\n",
        "\n",
        "# Function to get place details\n",
        "def get_place_details(place_id):\n",
        "    url = f\"https://maps.googleapis.com/maps/api/place/details/json?place_id={place_id}&key={API_KEY}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get('result', {})\n",
        "    return {}\n",
        "\n",
        "# Function to search places with pagination\n",
        "def search_places(query, location, next_page_token=None):\n",
        "    if next_page_token:\n",
        "        url = f\"https://maps.googleapis.com/maps/api/place/textsearch/json?pagetoken={next_page_token}&key={API_KEY}\"\n",
        "    else:\n",
        "        url = f\"https://maps.googleapis.com/maps/api/place/textsearch/json?query={query}&location={location}&key={API_KEY}\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    return {}\n",
        "\n",
        "# Function to scrape email from a website\n",
        "def scrape_email_from_website(url, visited=None, depth=0, max_depth=2):\n",
        "    if visited is None:\n",
        "        visited = set()\n",
        "    if depth > max_depth or url in visited:\n",
        "        return set()\n",
        "    visited.add(url)\n",
        "\n",
        "    emails = set()\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            text = soup.get_text()\n",
        "            emails.update(re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b', text))\n",
        "            # Look for links to \"Contact Us\" or similar pages\n",
        "            contact_links = soup.find_all('a', href=True)\n",
        "            for link in contact_links:\n",
        "                if 'contact' in link['href'].lower():\n",
        "                    contact_url = link['href']\n",
        "                    if not contact_url.startswith('http'):\n",
        "                        contact_url = url.rstrip('/') + '/' + contact_url.lstrip('/')\n",
        "                    emails.update(scrape_email_from_website(contact_url, visited, depth + 1, max_depth))\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Failed to retrieve {url}: {e}\")\n",
        "    return emails\n",
        "\n",
        "# Function to scrape email using Selenium\n",
        "def scrape_email_with_selenium(url, visited=None, depth=0, max_depth=2):\n",
        "    if visited is None:\n",
        "        visited = set()\n",
        "    if depth > max_depth or url in visited:\n",
        "        return set()\n",
        "    visited.add(url)\n",
        "\n",
        "    emails = set()\n",
        "    try:\n",
        "        options = Options()\n",
        "        options.headless = True\n",
        "        service = Service('path/to/chromedriver')  # Adjust path to your WebDriver\n",
        "        driver = webdriver.Chrome(service=service, options=options)\n",
        "        driver.get(url)\n",
        "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        text = soup.get_text()\n",
        "        emails.update(re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b', text))\n",
        "        contact_links = soup.find_all('a', href=True)\n",
        "        for link in contact_links:\n",
        "            if 'contact' in link['href'].lower():\n",
        "                contact_url = link['href']\n",
        "                if not contact_url.startswith('http'):\n",
        "                    contact_url = url.rstrip('/') + '/' + contact_url.lstrip('/')\n",
        "                emails.update(scrape_email_with_selenium(contact_url, visited, depth + 1, max_depth))\n",
        "        driver.quit()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to retrieve {url} with Selenium: {e}\")\n",
        "    return emails\n",
        "\n",
        "# Collect all results\n",
        "all_places = []\n",
        "next_page_token = None\n",
        "\n",
        "while len(all_places) < 500:  # Limit to 500 results\n",
        "    result = search_places(query, location, next_page_token)\n",
        "    places = result.get('results', [])\n",
        "    all_places.extend(places)\n",
        "\n",
        "    next_page_token = result.get('next_page_token')\n",
        "    if not next_page_token:\n",
        "        break\n",
        "\n",
        "    # Wait for the next page token to become valid\n",
        "    time.sleep(2)\n",
        "\n",
        "# Prepare a list to store the data\n",
        "data = []\n",
        "\n",
        "# Iterate over the places and get details\n",
        "for place in all_places:\n",
        "    place_id = place['place_id']\n",
        "    details = get_place_details(place_id)\n",
        "    name = details.get('name')\n",
        "    phone_number = details.get('formatted_phone_number')\n",
        "    address = details.get('formatted_address')\n",
        "    website = details.get('website')\n",
        "    email = None\n",
        "\n",
        "    if website:\n",
        "        emails = scrape_email_from_website(website)\n",
        "        if not emails:\n",
        "            emails = scrape_email_with_selenium(website)\n",
        "        email = ', '.join(emails)\n",
        "\n",
        "    data.append({\n",
        "        'Company Name': name,\n",
        "        'Phone Number': phone_number,\n",
        "        'Email': email,\n",
        "        'Website': website,\n",
        "        'Location': address\n",
        "    })\n",
        "\n",
        "# Convert the list to a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('QuebecCity.csv', index=False)\n",
        "\n",
        "print('QuebecCity.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ouequWHm7qpZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}